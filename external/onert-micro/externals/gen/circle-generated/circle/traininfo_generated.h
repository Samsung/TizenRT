// automatically generated by the FlatBuffers compiler, do not modify


#ifndef FLATBUFFERS_GENERATED_TRAININFO_CIRCLE_H_
#define FLATBUFFERS_GENERATED_TRAININFO_CIRCLE_H_

#include "externals/flatbuffers/flatbuffers.h"

namespace circle {

struct SGDOptions;
struct SGDOptionsBuilder;
struct SGDOptionsT;

struct AdamOptions;
struct AdamOptionsBuilder;
struct AdamOptionsT;

struct SparseCategoricalCrossentropyOptions;
struct SparseCategoricalCrossentropyOptionsBuilder;
struct SparseCategoricalCrossentropyOptionsT;

struct CategoricalCrossentropyOptions;
struct CategoricalCrossentropyOptionsBuilder;
struct CategoricalCrossentropyOptionsT;

struct MeanSquaredErrorOptions;
struct MeanSquaredErrorOptionsBuilder;
struct MeanSquaredErrorOptionsT;

struct ModelTraining;
struct ModelTrainingBuilder;
struct ModelTrainingT;

enum Optimizer : int8_t {
  Optimizer_SGD = 0,
  Optimizer_ADAM = 1,
  Optimizer_MIN = Optimizer_SGD,
  Optimizer_MAX = Optimizer_ADAM
};

inline const Optimizer (&EnumValuesOptimizer())[2] {
  static const Optimizer values[] = {
    Optimizer_SGD,
    Optimizer_ADAM
  };
  return values;
}

inline const char * const *EnumNamesOptimizer() {
  static const char * const names[3] = {
    "SGD",
    "ADAM",
    nullptr
  };
  return names;
}

inline const char *EnumNameOptimizer(Optimizer e) {
  if (flatbuffers::IsOutRange(e, Optimizer_SGD, Optimizer_ADAM)) return "";
  const size_t index = static_cast<size_t>(e);
  return EnumNamesOptimizer()[index];
}

enum OptimizerOptions : uint8_t {
  OptimizerOptions_NONE = 0,
  OptimizerOptions_SGDOptions = 1,
  OptimizerOptions_AdamOptions = 2,
  OptimizerOptions_MIN = OptimizerOptions_NONE,
  OptimizerOptions_MAX = OptimizerOptions_AdamOptions
};

inline const OptimizerOptions (&EnumValuesOptimizerOptions())[3] {
  static const OptimizerOptions values[] = {
    OptimizerOptions_NONE,
    OptimizerOptions_SGDOptions,
    OptimizerOptions_AdamOptions
  };
  return values;
}

inline const char * const *EnumNamesOptimizerOptions() {
  static const char * const names[4] = {
    "NONE",
    "SGDOptions",
    "AdamOptions",
    nullptr
  };
  return names;
}

inline const char *EnumNameOptimizerOptions(OptimizerOptions e) {
  if (flatbuffers::IsOutRange(e, OptimizerOptions_NONE, OptimizerOptions_AdamOptions)) return "";
  const size_t index = static_cast<size_t>(e);
  return EnumNamesOptimizerOptions()[index];
}

template<typename T> struct OptimizerOptionsTraits {
  static const OptimizerOptions enum_value = OptimizerOptions_NONE;
};

template<> struct OptimizerOptionsTraits<circle::SGDOptions> {
  static const OptimizerOptions enum_value = OptimizerOptions_SGDOptions;
};

template<> struct OptimizerOptionsTraits<circle::AdamOptions> {
  static const OptimizerOptions enum_value = OptimizerOptions_AdamOptions;
};

struct OptimizerOptionsUnion {
  OptimizerOptions type;
  void *value;

  OptimizerOptionsUnion() : type(OptimizerOptions_NONE), value(nullptr) {}
  OptimizerOptionsUnion(OptimizerOptionsUnion&& u) FLATBUFFERS_NOEXCEPT :
    type(OptimizerOptions_NONE), value(nullptr)
    { std::swap(type, u.type); std::swap(value, u.value); }
  OptimizerOptionsUnion(const OptimizerOptionsUnion &);
  OptimizerOptionsUnion &operator=(const OptimizerOptionsUnion &u)
    { OptimizerOptionsUnion t(u); std::swap(type, t.type); std::swap(value, t.value); return *this; }
  OptimizerOptionsUnion &operator=(OptimizerOptionsUnion &&u) FLATBUFFERS_NOEXCEPT
    { std::swap(type, u.type); std::swap(value, u.value); return *this; }
  ~OptimizerOptionsUnion() { Reset(); }

  void Reset();

#ifndef FLATBUFFERS_CPP98_STL
  template <typename T>
  void Set(T&& val) {
    using RT = typename std::remove_reference<T>::type;
    Reset();
    type = OptimizerOptionsTraits<typename RT::TableType>::enum_value;
    if (type != OptimizerOptions_NONE) {
      value = new RT(std::forward<T>(val));
    }
  }
#endif  // FLATBUFFERS_CPP98_STL

  static void *UnPack(const void *obj, OptimizerOptions type, const flatbuffers::resolver_function_t *resolver);
  flatbuffers::Offset<void> Pack(flatbuffers::FlatBufferBuilder &_fbb, const flatbuffers::rehasher_function_t *_rehasher = nullptr) const;

  circle::SGDOptionsT *AsSGDOptions() {
    return type == OptimizerOptions_SGDOptions ?
      reinterpret_cast<circle::SGDOptionsT *>(value) : nullptr;
  }
  const circle::SGDOptionsT *AsSGDOptions() const {
    return type == OptimizerOptions_SGDOptions ?
      reinterpret_cast<const circle::SGDOptionsT *>(value) : nullptr;
  }
  circle::AdamOptionsT *AsAdamOptions() {
    return type == OptimizerOptions_AdamOptions ?
      reinterpret_cast<circle::AdamOptionsT *>(value) : nullptr;
  }
  const circle::AdamOptionsT *AsAdamOptions() const {
    return type == OptimizerOptions_AdamOptions ?
      reinterpret_cast<const circle::AdamOptionsT *>(value) : nullptr;
  }
};

bool VerifyOptimizerOptions(flatbuffers::Verifier &verifier, const void *obj, OptimizerOptions type);
bool VerifyOptimizerOptionsVector(flatbuffers::Verifier &verifier, const flatbuffers::Vector<flatbuffers::Offset<void>> *values, const flatbuffers::Vector<uint8_t> *types);

enum LossFn : int8_t {
  LossFn_SPARSE_CATEGORICAL_CROSSENTROPY = 0,
  LossFn_CATEGORICAL_CROSSENTROPY = 1,
  LossFn_MEAN_SQUARED_ERROR = 2,
  LossFn_MIN = LossFn_SPARSE_CATEGORICAL_CROSSENTROPY,
  LossFn_MAX = LossFn_MEAN_SQUARED_ERROR
};

inline const LossFn (&EnumValuesLossFn())[3] {
  static const LossFn values[] = {
    LossFn_SPARSE_CATEGORICAL_CROSSENTROPY,
    LossFn_CATEGORICAL_CROSSENTROPY,
    LossFn_MEAN_SQUARED_ERROR
  };
  return values;
}

inline const char * const *EnumNamesLossFn() {
  static const char * const names[4] = {
    "SPARSE_CATEGORICAL_CROSSENTROPY",
    "CATEGORICAL_CROSSENTROPY",
    "MEAN_SQUARED_ERROR",
    nullptr
  };
  return names;
}

inline const char *EnumNameLossFn(LossFn e) {
  if (flatbuffers::IsOutRange(e, LossFn_SPARSE_CATEGORICAL_CROSSENTROPY, LossFn_MEAN_SQUARED_ERROR)) return "";
  const size_t index = static_cast<size_t>(e);
  return EnumNamesLossFn()[index];
}

enum LossFnOptions : uint8_t {
  LossFnOptions_NONE = 0,
  LossFnOptions_SparseCategoricalCrossentropyOptions = 1,
  LossFnOptions_CategoricalCrossentropyOptions = 2,
  LossFnOptions_MeanSquaredErrorOptions = 3,
  LossFnOptions_MIN = LossFnOptions_NONE,
  LossFnOptions_MAX = LossFnOptions_MeanSquaredErrorOptions
};

inline const LossFnOptions (&EnumValuesLossFnOptions())[4] {
  static const LossFnOptions values[] = {
    LossFnOptions_NONE,
    LossFnOptions_SparseCategoricalCrossentropyOptions,
    LossFnOptions_CategoricalCrossentropyOptions,
    LossFnOptions_MeanSquaredErrorOptions
  };
  return values;
}

inline const char * const *EnumNamesLossFnOptions() {
  static const char * const names[5] = {
    "NONE",
    "SparseCategoricalCrossentropyOptions",
    "CategoricalCrossentropyOptions",
    "MeanSquaredErrorOptions",
    nullptr
  };
  return names;
}

inline const char *EnumNameLossFnOptions(LossFnOptions e) {
  if (flatbuffers::IsOutRange(e, LossFnOptions_NONE, LossFnOptions_MeanSquaredErrorOptions)) return "";
  const size_t index = static_cast<size_t>(e);
  return EnumNamesLossFnOptions()[index];
}

template<typename T> struct LossFnOptionsTraits {
  static const LossFnOptions enum_value = LossFnOptions_NONE;
};

template<> struct LossFnOptionsTraits<circle::SparseCategoricalCrossentropyOptions> {
  static const LossFnOptions enum_value = LossFnOptions_SparseCategoricalCrossentropyOptions;
};

template<> struct LossFnOptionsTraits<circle::CategoricalCrossentropyOptions> {
  static const LossFnOptions enum_value = LossFnOptions_CategoricalCrossentropyOptions;
};

template<> struct LossFnOptionsTraits<circle::MeanSquaredErrorOptions> {
  static const LossFnOptions enum_value = LossFnOptions_MeanSquaredErrorOptions;
};

struct LossFnOptionsUnion {
  LossFnOptions type;
  void *value;

  LossFnOptionsUnion() : type(LossFnOptions_NONE), value(nullptr) {}
  LossFnOptionsUnion(LossFnOptionsUnion&& u) FLATBUFFERS_NOEXCEPT :
    type(LossFnOptions_NONE), value(nullptr)
    { std::swap(type, u.type); std::swap(value, u.value); }
  LossFnOptionsUnion(const LossFnOptionsUnion &);
  LossFnOptionsUnion &operator=(const LossFnOptionsUnion &u)
    { LossFnOptionsUnion t(u); std::swap(type, t.type); std::swap(value, t.value); return *this; }
  LossFnOptionsUnion &operator=(LossFnOptionsUnion &&u) FLATBUFFERS_NOEXCEPT
    { std::swap(type, u.type); std::swap(value, u.value); return *this; }
  ~LossFnOptionsUnion() { Reset(); }

  void Reset();

#ifndef FLATBUFFERS_CPP98_STL
  template <typename T>
  void Set(T&& val) {
    using RT = typename std::remove_reference<T>::type;
    Reset();
    type = LossFnOptionsTraits<typename RT::TableType>::enum_value;
    if (type != LossFnOptions_NONE) {
      value = new RT(std::forward<T>(val));
    }
  }
#endif  // FLATBUFFERS_CPP98_STL

  static void *UnPack(const void *obj, LossFnOptions type, const flatbuffers::resolver_function_t *resolver);
  flatbuffers::Offset<void> Pack(flatbuffers::FlatBufferBuilder &_fbb, const flatbuffers::rehasher_function_t *_rehasher = nullptr) const;

  circle::SparseCategoricalCrossentropyOptionsT *AsSparseCategoricalCrossentropyOptions() {
    return type == LossFnOptions_SparseCategoricalCrossentropyOptions ?
      reinterpret_cast<circle::SparseCategoricalCrossentropyOptionsT *>(value) : nullptr;
  }
  const circle::SparseCategoricalCrossentropyOptionsT *AsSparseCategoricalCrossentropyOptions() const {
    return type == LossFnOptions_SparseCategoricalCrossentropyOptions ?
      reinterpret_cast<const circle::SparseCategoricalCrossentropyOptionsT *>(value) : nullptr;
  }
  circle::CategoricalCrossentropyOptionsT *AsCategoricalCrossentropyOptions() {
    return type == LossFnOptions_CategoricalCrossentropyOptions ?
      reinterpret_cast<circle::CategoricalCrossentropyOptionsT *>(value) : nullptr;
  }
  const circle::CategoricalCrossentropyOptionsT *AsCategoricalCrossentropyOptions() const {
    return type == LossFnOptions_CategoricalCrossentropyOptions ?
      reinterpret_cast<const circle::CategoricalCrossentropyOptionsT *>(value) : nullptr;
  }
  circle::MeanSquaredErrorOptionsT *AsMeanSquaredErrorOptions() {
    return type == LossFnOptions_MeanSquaredErrorOptions ?
      reinterpret_cast<circle::MeanSquaredErrorOptionsT *>(value) : nullptr;
  }
  const circle::MeanSquaredErrorOptionsT *AsMeanSquaredErrorOptions() const {
    return type == LossFnOptions_MeanSquaredErrorOptions ?
      reinterpret_cast<const circle::MeanSquaredErrorOptionsT *>(value) : nullptr;
  }
};

bool VerifyLossFnOptions(flatbuffers::Verifier &verifier, const void *obj, LossFnOptions type);
bool VerifyLossFnOptionsVector(flatbuffers::Verifier &verifier, const flatbuffers::Vector<flatbuffers::Offset<void>> *values, const flatbuffers::Vector<uint8_t> *types);

enum LossReductionType : int8_t {
  LossReductionType_SumOverBatchSize = 0,
  LossReductionType_Sum = 1,
  LossReductionType_MIN = LossReductionType_SumOverBatchSize,
  LossReductionType_MAX = LossReductionType_Sum
};

inline const LossReductionType (&EnumValuesLossReductionType())[2] {
  static const LossReductionType values[] = {
    LossReductionType_SumOverBatchSize,
    LossReductionType_Sum
  };
  return values;
}

inline const char * const *EnumNamesLossReductionType() {
  static const char * const names[3] = {
    "SumOverBatchSize",
    "Sum",
    nullptr
  };
  return names;
}

inline const char *EnumNameLossReductionType(LossReductionType e) {
  if (flatbuffers::IsOutRange(e, LossReductionType_SumOverBatchSize, LossReductionType_Sum)) return "";
  const size_t index = static_cast<size_t>(e);
  return EnumNamesLossReductionType()[index];
}

struct SGDOptionsT : public flatbuffers::NativeTable {
  typedef SGDOptions TableType;
  float learning_rate = 0.0f;
};

struct SGDOptions FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
  typedef SGDOptionsT NativeTableType;
  typedef SGDOptionsBuilder Builder;
  enum FlatBuffersVTableOffset FLATBUFFERS_VTABLE_UNDERLYING_TYPE {
    VT_LEARNING_RATE = 4
  };
  float learning_rate() const {
    return GetField<float>(VT_LEARNING_RATE, 0.0f);
  }
  bool Verify(flatbuffers::Verifier &verifier) const {
    return VerifyTableStart(verifier) &&
           VerifyField<float>(verifier, VT_LEARNING_RATE) &&
           verifier.EndTable();
  }
  SGDOptionsT *UnPack(const flatbuffers::resolver_function_t *_resolver = nullptr) const;
  void UnPackTo(SGDOptionsT *_o, const flatbuffers::resolver_function_t *_resolver = nullptr) const;
  static flatbuffers::Offset<SGDOptions> Pack(flatbuffers::FlatBufferBuilder &_fbb, const SGDOptionsT* _o, const flatbuffers::rehasher_function_t *_rehasher = nullptr);
};

struct SGDOptionsBuilder {
  typedef SGDOptions Table;
  flatbuffers::FlatBufferBuilder &fbb_;
  flatbuffers::uoffset_t start_;
  void add_learning_rate(float learning_rate) {
    fbb_.AddElement<float>(SGDOptions::VT_LEARNING_RATE, learning_rate, 0.0f);
  }
  explicit SGDOptionsBuilder(flatbuffers::FlatBufferBuilder &_fbb)
        : fbb_(_fbb) {
    start_ = fbb_.StartTable();
  }
  flatbuffers::Offset<SGDOptions> Finish() {
    const auto end = fbb_.EndTable(start_);
    auto o = flatbuffers::Offset<SGDOptions>(end);
    return o;
  }
};

inline flatbuffers::Offset<SGDOptions> CreateSGDOptions(
    flatbuffers::FlatBufferBuilder &_fbb,
    float learning_rate = 0.0f) {
  SGDOptionsBuilder builder_(_fbb);
  builder_.add_learning_rate(learning_rate);
  return builder_.Finish();
}

flatbuffers::Offset<SGDOptions> CreateSGDOptions(flatbuffers::FlatBufferBuilder &_fbb, const SGDOptionsT *_o, const flatbuffers::rehasher_function_t *_rehasher = nullptr);

struct AdamOptionsT : public flatbuffers::NativeTable {
  typedef AdamOptions TableType;
  float learning_rate = 0.0f;
  float beta_1 = 0.0f;
  float beta_2 = 0.0f;
  float epsilon = 0.0f;
};

struct AdamOptions FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
  typedef AdamOptionsT NativeTableType;
  typedef AdamOptionsBuilder Builder;
  enum FlatBuffersVTableOffset FLATBUFFERS_VTABLE_UNDERLYING_TYPE {
    VT_LEARNING_RATE = 4,
    VT_BETA_1 = 6,
    VT_BETA_2 = 8,
    VT_EPSILON = 10
  };
  float learning_rate() const {
    return GetField<float>(VT_LEARNING_RATE, 0.0f);
  }
  float beta_1() const {
    return GetField<float>(VT_BETA_1, 0.0f);
  }
  float beta_2() const {
    return GetField<float>(VT_BETA_2, 0.0f);
  }
  float epsilon() const {
    return GetField<float>(VT_EPSILON, 0.0f);
  }
  bool Verify(flatbuffers::Verifier &verifier) const {
    return VerifyTableStart(verifier) &&
           VerifyField<float>(verifier, VT_LEARNING_RATE) &&
           VerifyField<float>(verifier, VT_BETA_1) &&
           VerifyField<float>(verifier, VT_BETA_2) &&
           VerifyField<float>(verifier, VT_EPSILON) &&
           verifier.EndTable();
  }
  AdamOptionsT *UnPack(const flatbuffers::resolver_function_t *_resolver = nullptr) const;
  void UnPackTo(AdamOptionsT *_o, const flatbuffers::resolver_function_t *_resolver = nullptr) const;
  static flatbuffers::Offset<AdamOptions> Pack(flatbuffers::FlatBufferBuilder &_fbb, const AdamOptionsT* _o, const flatbuffers::rehasher_function_t *_rehasher = nullptr);
};

struct AdamOptionsBuilder {
  typedef AdamOptions Table;
  flatbuffers::FlatBufferBuilder &fbb_;
  flatbuffers::uoffset_t start_;
  void add_learning_rate(float learning_rate) {
    fbb_.AddElement<float>(AdamOptions::VT_LEARNING_RATE, learning_rate, 0.0f);
  }
  void add_beta_1(float beta_1) {
    fbb_.AddElement<float>(AdamOptions::VT_BETA_1, beta_1, 0.0f);
  }
  void add_beta_2(float beta_2) {
    fbb_.AddElement<float>(AdamOptions::VT_BETA_2, beta_2, 0.0f);
  }
  void add_epsilon(float epsilon) {
    fbb_.AddElement<float>(AdamOptions::VT_EPSILON, epsilon, 0.0f);
  }
  explicit AdamOptionsBuilder(flatbuffers::FlatBufferBuilder &_fbb)
        : fbb_(_fbb) {
    start_ = fbb_.StartTable();
  }
  flatbuffers::Offset<AdamOptions> Finish() {
    const auto end = fbb_.EndTable(start_);
    auto o = flatbuffers::Offset<AdamOptions>(end);
    return o;
  }
};

inline flatbuffers::Offset<AdamOptions> CreateAdamOptions(
    flatbuffers::FlatBufferBuilder &_fbb,
    float learning_rate = 0.0f,
    float beta_1 = 0.0f,
    float beta_2 = 0.0f,
    float epsilon = 0.0f) {
  AdamOptionsBuilder builder_(_fbb);
  builder_.add_epsilon(epsilon);
  builder_.add_beta_2(beta_2);
  builder_.add_beta_1(beta_1);
  builder_.add_learning_rate(learning_rate);
  return builder_.Finish();
}

flatbuffers::Offset<AdamOptions> CreateAdamOptions(flatbuffers::FlatBufferBuilder &_fbb, const AdamOptionsT *_o, const flatbuffers::rehasher_function_t *_rehasher = nullptr);

struct SparseCategoricalCrossentropyOptionsT : public flatbuffers::NativeTable {
  typedef SparseCategoricalCrossentropyOptions TableType;
  bool from_logits = false;
};

struct SparseCategoricalCrossentropyOptions FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
  typedef SparseCategoricalCrossentropyOptionsT NativeTableType;
  typedef SparseCategoricalCrossentropyOptionsBuilder Builder;
  enum FlatBuffersVTableOffset FLATBUFFERS_VTABLE_UNDERLYING_TYPE {
    VT_FROM_LOGITS = 4
  };
  bool from_logits() const {
    return GetField<uint8_t>(VT_FROM_LOGITS, 0) != 0;
  }
  bool Verify(flatbuffers::Verifier &verifier) const {
    return VerifyTableStart(verifier) &&
           VerifyField<uint8_t>(verifier, VT_FROM_LOGITS) &&
           verifier.EndTable();
  }
  SparseCategoricalCrossentropyOptionsT *UnPack(const flatbuffers::resolver_function_t *_resolver = nullptr) const;
  void UnPackTo(SparseCategoricalCrossentropyOptionsT *_o, const flatbuffers::resolver_function_t *_resolver = nullptr) const;
  static flatbuffers::Offset<SparseCategoricalCrossentropyOptions> Pack(flatbuffers::FlatBufferBuilder &_fbb, const SparseCategoricalCrossentropyOptionsT* _o, const flatbuffers::rehasher_function_t *_rehasher = nullptr);
};

struct SparseCategoricalCrossentropyOptionsBuilder {
  typedef SparseCategoricalCrossentropyOptions Table;
  flatbuffers::FlatBufferBuilder &fbb_;
  flatbuffers::uoffset_t start_;
  void add_from_logits(bool from_logits) {
    fbb_.AddElement<uint8_t>(SparseCategoricalCrossentropyOptions::VT_FROM_LOGITS, static_cast<uint8_t>(from_logits), 0);
  }
  explicit SparseCategoricalCrossentropyOptionsBuilder(flatbuffers::FlatBufferBuilder &_fbb)
        : fbb_(_fbb) {
    start_ = fbb_.StartTable();
  }
  flatbuffers::Offset<SparseCategoricalCrossentropyOptions> Finish() {
    const auto end = fbb_.EndTable(start_);
    auto o = flatbuffers::Offset<SparseCategoricalCrossentropyOptions>(end);
    return o;
  }
};

inline flatbuffers::Offset<SparseCategoricalCrossentropyOptions> CreateSparseCategoricalCrossentropyOptions(
    flatbuffers::FlatBufferBuilder &_fbb,
    bool from_logits = false) {
  SparseCategoricalCrossentropyOptionsBuilder builder_(_fbb);
  builder_.add_from_logits(from_logits);
  return builder_.Finish();
}

flatbuffers::Offset<SparseCategoricalCrossentropyOptions> CreateSparseCategoricalCrossentropyOptions(flatbuffers::FlatBufferBuilder &_fbb, const SparseCategoricalCrossentropyOptionsT *_o, const flatbuffers::rehasher_function_t *_rehasher = nullptr);

struct CategoricalCrossentropyOptionsT : public flatbuffers::NativeTable {
  typedef CategoricalCrossentropyOptions TableType;
  bool from_logits = false;
};

struct CategoricalCrossentropyOptions FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
  typedef CategoricalCrossentropyOptionsT NativeTableType;
  typedef CategoricalCrossentropyOptionsBuilder Builder;
  enum FlatBuffersVTableOffset FLATBUFFERS_VTABLE_UNDERLYING_TYPE {
    VT_FROM_LOGITS = 4
  };
  bool from_logits() const {
    return GetField<uint8_t>(VT_FROM_LOGITS, 0) != 0;
  }
  bool Verify(flatbuffers::Verifier &verifier) const {
    return VerifyTableStart(verifier) &&
           VerifyField<uint8_t>(verifier, VT_FROM_LOGITS) &&
           verifier.EndTable();
  }
  CategoricalCrossentropyOptionsT *UnPack(const flatbuffers::resolver_function_t *_resolver = nullptr) const;
  void UnPackTo(CategoricalCrossentropyOptionsT *_o, const flatbuffers::resolver_function_t *_resolver = nullptr) const;
  static flatbuffers::Offset<CategoricalCrossentropyOptions> Pack(flatbuffers::FlatBufferBuilder &_fbb, const CategoricalCrossentropyOptionsT* _o, const flatbuffers::rehasher_function_t *_rehasher = nullptr);
};

struct CategoricalCrossentropyOptionsBuilder {
  typedef CategoricalCrossentropyOptions Table;
  flatbuffers::FlatBufferBuilder &fbb_;
  flatbuffers::uoffset_t start_;
  void add_from_logits(bool from_logits) {
    fbb_.AddElement<uint8_t>(CategoricalCrossentropyOptions::VT_FROM_LOGITS, static_cast<uint8_t>(from_logits), 0);
  }
  explicit CategoricalCrossentropyOptionsBuilder(flatbuffers::FlatBufferBuilder &_fbb)
        : fbb_(_fbb) {
    start_ = fbb_.StartTable();
  }
  flatbuffers::Offset<CategoricalCrossentropyOptions> Finish() {
    const auto end = fbb_.EndTable(start_);
    auto o = flatbuffers::Offset<CategoricalCrossentropyOptions>(end);
    return o;
  }
};

inline flatbuffers::Offset<CategoricalCrossentropyOptions> CreateCategoricalCrossentropyOptions(
    flatbuffers::FlatBufferBuilder &_fbb,
    bool from_logits = false) {
  CategoricalCrossentropyOptionsBuilder builder_(_fbb);
  builder_.add_from_logits(from_logits);
  return builder_.Finish();
}

flatbuffers::Offset<CategoricalCrossentropyOptions> CreateCategoricalCrossentropyOptions(flatbuffers::FlatBufferBuilder &_fbb, const CategoricalCrossentropyOptionsT *_o, const flatbuffers::rehasher_function_t *_rehasher = nullptr);

struct MeanSquaredErrorOptionsT : public flatbuffers::NativeTable {
  typedef MeanSquaredErrorOptions TableType;
};

struct MeanSquaredErrorOptions FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
  typedef MeanSquaredErrorOptionsT NativeTableType;
  typedef MeanSquaredErrorOptionsBuilder Builder;
  bool Verify(flatbuffers::Verifier &verifier) const {
    return VerifyTableStart(verifier) &&
           verifier.EndTable();
  }
  MeanSquaredErrorOptionsT *UnPack(const flatbuffers::resolver_function_t *_resolver = nullptr) const;
  void UnPackTo(MeanSquaredErrorOptionsT *_o, const flatbuffers::resolver_function_t *_resolver = nullptr) const;
  static flatbuffers::Offset<MeanSquaredErrorOptions> Pack(flatbuffers::FlatBufferBuilder &_fbb, const MeanSquaredErrorOptionsT* _o, const flatbuffers::rehasher_function_t *_rehasher = nullptr);
};

struct MeanSquaredErrorOptionsBuilder {
  typedef MeanSquaredErrorOptions Table;
  flatbuffers::FlatBufferBuilder &fbb_;
  flatbuffers::uoffset_t start_;
  explicit MeanSquaredErrorOptionsBuilder(flatbuffers::FlatBufferBuilder &_fbb)
        : fbb_(_fbb) {
    start_ = fbb_.StartTable();
  }
  flatbuffers::Offset<MeanSquaredErrorOptions> Finish() {
    const auto end = fbb_.EndTable(start_);
    auto o = flatbuffers::Offset<MeanSquaredErrorOptions>(end);
    return o;
  }
};

inline flatbuffers::Offset<MeanSquaredErrorOptions> CreateMeanSquaredErrorOptions(
    flatbuffers::FlatBufferBuilder &_fbb) {
  MeanSquaredErrorOptionsBuilder builder_(_fbb);
  return builder_.Finish();
}

flatbuffers::Offset<MeanSquaredErrorOptions> CreateMeanSquaredErrorOptions(flatbuffers::FlatBufferBuilder &_fbb, const MeanSquaredErrorOptionsT *_o, const flatbuffers::rehasher_function_t *_rehasher = nullptr);

struct ModelTrainingT : public flatbuffers::NativeTable {
  typedef ModelTraining TableType;
  uint32_t version = 0;
  circle::Optimizer optimizer = circle::Optimizer_SGD;
  circle::OptimizerOptionsUnion optimizer_opt{};
  circle::LossFn lossfn = circle::LossFn_SPARSE_CATEGORICAL_CROSSENTROPY;
  circle::LossFnOptionsUnion lossfn_opt{};
  int32_t epochs = 0;
  int32_t batch_size = 0;
  circle::LossReductionType loss_reduction_type = circle::LossReductionType_SumOverBatchSize;
  std::vector<int32_t> trainable_ops{};
};

struct ModelTraining FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
  typedef ModelTrainingT NativeTableType;
  typedef ModelTrainingBuilder Builder;
  enum FlatBuffersVTableOffset FLATBUFFERS_VTABLE_UNDERLYING_TYPE {
    VT_VERSION = 4,
    VT_OPTIMIZER = 6,
    VT_OPTIMIZER_OPT_TYPE = 8,
    VT_OPTIMIZER_OPT = 10,
    VT_LOSSFN = 12,
    VT_LOSSFN_OPT_TYPE = 14,
    VT_LOSSFN_OPT = 16,
    VT_EPOCHS = 18,
    VT_BATCH_SIZE = 20,
    VT_LOSS_REDUCTION_TYPE = 22,
    VT_TRAINABLE_OPS = 24
  };
  uint32_t version() const {
    return GetField<uint32_t>(VT_VERSION, 0);
  }
  circle::Optimizer optimizer() const {
    return static_cast<circle::Optimizer>(GetField<int8_t>(VT_OPTIMIZER, 0));
  }
  circle::OptimizerOptions optimizer_opt_type() const {
    return static_cast<circle::OptimizerOptions>(GetField<uint8_t>(VT_OPTIMIZER_OPT_TYPE, 0));
  }
  const void *optimizer_opt() const {
    return GetPointer<const void *>(VT_OPTIMIZER_OPT);
  }
  template<typename T> const T *optimizer_opt_as() const;
  const circle::SGDOptions *optimizer_opt_as_SGDOptions() const {
    return optimizer_opt_type() == circle::OptimizerOptions_SGDOptions ? static_cast<const circle::SGDOptions *>(optimizer_opt()) : nullptr;
  }
  const circle::AdamOptions *optimizer_opt_as_AdamOptions() const {
    return optimizer_opt_type() == circle::OptimizerOptions_AdamOptions ? static_cast<const circle::AdamOptions *>(optimizer_opt()) : nullptr;
  }
  circle::LossFn lossfn() const {
    return static_cast<circle::LossFn>(GetField<int8_t>(VT_LOSSFN, 0));
  }
  circle::LossFnOptions lossfn_opt_type() const {
    return static_cast<circle::LossFnOptions>(GetField<uint8_t>(VT_LOSSFN_OPT_TYPE, 0));
  }
  const void *lossfn_opt() const {
    return GetPointer<const void *>(VT_LOSSFN_OPT);
  }
  template<typename T> const T *lossfn_opt_as() const;
  const circle::SparseCategoricalCrossentropyOptions *lossfn_opt_as_SparseCategoricalCrossentropyOptions() const {
    return lossfn_opt_type() == circle::LossFnOptions_SparseCategoricalCrossentropyOptions ? static_cast<const circle::SparseCategoricalCrossentropyOptions *>(lossfn_opt()) : nullptr;
  }
  const circle::CategoricalCrossentropyOptions *lossfn_opt_as_CategoricalCrossentropyOptions() const {
    return lossfn_opt_type() == circle::LossFnOptions_CategoricalCrossentropyOptions ? static_cast<const circle::CategoricalCrossentropyOptions *>(lossfn_opt()) : nullptr;
  }
  const circle::MeanSquaredErrorOptions *lossfn_opt_as_MeanSquaredErrorOptions() const {
    return lossfn_opt_type() == circle::LossFnOptions_MeanSquaredErrorOptions ? static_cast<const circle::MeanSquaredErrorOptions *>(lossfn_opt()) : nullptr;
  }
  int32_t epochs() const {
    return GetField<int32_t>(VT_EPOCHS, 0);
  }
  int32_t batch_size() const {
    return GetField<int32_t>(VT_BATCH_SIZE, 0);
  }
  circle::LossReductionType loss_reduction_type() const {
    return static_cast<circle::LossReductionType>(GetField<int8_t>(VT_LOSS_REDUCTION_TYPE, 0));
  }
  const flatbuffers::Vector<int32_t> *trainable_ops() const {
    return GetPointer<const flatbuffers::Vector<int32_t> *>(VT_TRAINABLE_OPS);
  }
  bool Verify(flatbuffers::Verifier &verifier) const {
    return VerifyTableStart(verifier) &&
           VerifyField<uint32_t>(verifier, VT_VERSION) &&
           VerifyField<int8_t>(verifier, VT_OPTIMIZER) &&
           VerifyField<uint8_t>(verifier, VT_OPTIMIZER_OPT_TYPE) &&
           VerifyOffset(verifier, VT_OPTIMIZER_OPT) &&
           VerifyOptimizerOptions(verifier, optimizer_opt(), optimizer_opt_type()) &&
           VerifyField<int8_t>(verifier, VT_LOSSFN) &&
           VerifyField<uint8_t>(verifier, VT_LOSSFN_OPT_TYPE) &&
           VerifyOffset(verifier, VT_LOSSFN_OPT) &&
           VerifyLossFnOptions(verifier, lossfn_opt(), lossfn_opt_type()) &&
           VerifyField<int32_t>(verifier, VT_EPOCHS) &&
           VerifyField<int32_t>(verifier, VT_BATCH_SIZE) &&
           VerifyField<int8_t>(verifier, VT_LOSS_REDUCTION_TYPE) &&
           VerifyOffset(verifier, VT_TRAINABLE_OPS) &&
           verifier.VerifyVector(trainable_ops()) &&
           verifier.EndTable();
  }
  ModelTrainingT *UnPack(const flatbuffers::resolver_function_t *_resolver = nullptr) const;
  void UnPackTo(ModelTrainingT *_o, const flatbuffers::resolver_function_t *_resolver = nullptr) const;
  static flatbuffers::Offset<ModelTraining> Pack(flatbuffers::FlatBufferBuilder &_fbb, const ModelTrainingT* _o, const flatbuffers::rehasher_function_t *_rehasher = nullptr);
};

template<> inline const circle::SGDOptions *ModelTraining::optimizer_opt_as<circle::SGDOptions>() const {
  return optimizer_opt_as_SGDOptions();
}

template<> inline const circle::AdamOptions *ModelTraining::optimizer_opt_as<circle::AdamOptions>() const {
  return optimizer_opt_as_AdamOptions();
}

template<> inline const circle::SparseCategoricalCrossentropyOptions *ModelTraining::lossfn_opt_as<circle::SparseCategoricalCrossentropyOptions>() const {
  return lossfn_opt_as_SparseCategoricalCrossentropyOptions();
}

template<> inline const circle::CategoricalCrossentropyOptions *ModelTraining::lossfn_opt_as<circle::CategoricalCrossentropyOptions>() const {
  return lossfn_opt_as_CategoricalCrossentropyOptions();
}

template<> inline const circle::MeanSquaredErrorOptions *ModelTraining::lossfn_opt_as<circle::MeanSquaredErrorOptions>() const {
  return lossfn_opt_as_MeanSquaredErrorOptions();
}

struct ModelTrainingBuilder {
  typedef ModelTraining Table;
  flatbuffers::FlatBufferBuilder &fbb_;
  flatbuffers::uoffset_t start_;
  void add_version(uint32_t version) {
    fbb_.AddElement<uint32_t>(ModelTraining::VT_VERSION, version, 0);
  }
  void add_optimizer(circle::Optimizer optimizer) {
    fbb_.AddElement<int8_t>(ModelTraining::VT_OPTIMIZER, static_cast<int8_t>(optimizer), 0);
  }
  void add_optimizer_opt_type(circle::OptimizerOptions optimizer_opt_type) {
    fbb_.AddElement<uint8_t>(ModelTraining::VT_OPTIMIZER_OPT_TYPE, static_cast<uint8_t>(optimizer_opt_type), 0);
  }
  void add_optimizer_opt(flatbuffers::Offset<void> optimizer_opt) {
    fbb_.AddOffset(ModelTraining::VT_OPTIMIZER_OPT, optimizer_opt);
  }
  void add_lossfn(circle::LossFn lossfn) {
    fbb_.AddElement<int8_t>(ModelTraining::VT_LOSSFN, static_cast<int8_t>(lossfn), 0);
  }
  void add_lossfn_opt_type(circle::LossFnOptions lossfn_opt_type) {
    fbb_.AddElement<uint8_t>(ModelTraining::VT_LOSSFN_OPT_TYPE, static_cast<uint8_t>(lossfn_opt_type), 0);
  }
  void add_lossfn_opt(flatbuffers::Offset<void> lossfn_opt) {
    fbb_.AddOffset(ModelTraining::VT_LOSSFN_OPT, lossfn_opt);
  }
  void add_epochs(int32_t epochs) {
    fbb_.AddElement<int32_t>(ModelTraining::VT_EPOCHS, epochs, 0);
  }
  void add_batch_size(int32_t batch_size) {
    fbb_.AddElement<int32_t>(ModelTraining::VT_BATCH_SIZE, batch_size, 0);
  }
  void add_loss_reduction_type(circle::LossReductionType loss_reduction_type) {
    fbb_.AddElement<int8_t>(ModelTraining::VT_LOSS_REDUCTION_TYPE, static_cast<int8_t>(loss_reduction_type), 0);
  }
  void add_trainable_ops(flatbuffers::Offset<flatbuffers::Vector<int32_t>> trainable_ops) {
    fbb_.AddOffset(ModelTraining::VT_TRAINABLE_OPS, trainable_ops);
  }
  explicit ModelTrainingBuilder(flatbuffers::FlatBufferBuilder &_fbb)
        : fbb_(_fbb) {
    start_ = fbb_.StartTable();
  }
  flatbuffers::Offset<ModelTraining> Finish() {
    const auto end = fbb_.EndTable(start_);
    auto o = flatbuffers::Offset<ModelTraining>(end);
    return o;
  }
};

inline flatbuffers::Offset<ModelTraining> CreateModelTraining(
    flatbuffers::FlatBufferBuilder &_fbb,
    uint32_t version = 0,
    circle::Optimizer optimizer = circle::Optimizer_SGD,
    circle::OptimizerOptions optimizer_opt_type = circle::OptimizerOptions_NONE,
    flatbuffers::Offset<void> optimizer_opt = 0,
    circle::LossFn lossfn = circle::LossFn_SPARSE_CATEGORICAL_CROSSENTROPY,
    circle::LossFnOptions lossfn_opt_type = circle::LossFnOptions_NONE,
    flatbuffers::Offset<void> lossfn_opt = 0,
    int32_t epochs = 0,
    int32_t batch_size = 0,
    circle::LossReductionType loss_reduction_type = circle::LossReductionType_SumOverBatchSize,
    flatbuffers::Offset<flatbuffers::Vector<int32_t>> trainable_ops = 0) {
  ModelTrainingBuilder builder_(_fbb);
  builder_.add_trainable_ops(trainable_ops);
  builder_.add_batch_size(batch_size);
  builder_.add_epochs(epochs);
  builder_.add_lossfn_opt(lossfn_opt);
  builder_.add_optimizer_opt(optimizer_opt);
  builder_.add_version(version);
  builder_.add_loss_reduction_type(loss_reduction_type);
  builder_.add_lossfn_opt_type(lossfn_opt_type);
  builder_.add_lossfn(lossfn);
  builder_.add_optimizer_opt_type(optimizer_opt_type);
  builder_.add_optimizer(optimizer);
  return builder_.Finish();
}

inline flatbuffers::Offset<ModelTraining> CreateModelTrainingDirect(
    flatbuffers::FlatBufferBuilder &_fbb,
    uint32_t version = 0,
    circle::Optimizer optimizer = circle::Optimizer_SGD,
    circle::OptimizerOptions optimizer_opt_type = circle::OptimizerOptions_NONE,
    flatbuffers::Offset<void> optimizer_opt = 0,
    circle::LossFn lossfn = circle::LossFn_SPARSE_CATEGORICAL_CROSSENTROPY,
    circle::LossFnOptions lossfn_opt_type = circle::LossFnOptions_NONE,
    flatbuffers::Offset<void> lossfn_opt = 0,
    int32_t epochs = 0,
    int32_t batch_size = 0,
    circle::LossReductionType loss_reduction_type = circle::LossReductionType_SumOverBatchSize,
    const std::vector<int32_t> *trainable_ops = nullptr) {
  auto trainable_ops__ = trainable_ops ? _fbb.CreateVector<int32_t>(*trainable_ops) : 0;
  return circle::CreateModelTraining(
      _fbb,
      version,
      optimizer,
      optimizer_opt_type,
      optimizer_opt,
      lossfn,
      lossfn_opt_type,
      lossfn_opt,
      epochs,
      batch_size,
      loss_reduction_type,
      trainable_ops__);
}

flatbuffers::Offset<ModelTraining> CreateModelTraining(flatbuffers::FlatBufferBuilder &_fbb, const ModelTrainingT *_o, const flatbuffers::rehasher_function_t *_rehasher = nullptr);

inline SGDOptionsT *SGDOptions::UnPack(const flatbuffers::resolver_function_t *_resolver) const {
  auto _o = std::unique_ptr<SGDOptionsT>(new SGDOptionsT());
  UnPackTo(_o.get(), _resolver);
  return _o.release();
}

inline void SGDOptions::UnPackTo(SGDOptionsT *_o, const flatbuffers::resolver_function_t *_resolver) const {
  (void)_o;
  (void)_resolver;
  { auto _e = learning_rate(); _o->learning_rate = _e; }
}

inline flatbuffers::Offset<SGDOptions> SGDOptions::Pack(flatbuffers::FlatBufferBuilder &_fbb, const SGDOptionsT* _o, const flatbuffers::rehasher_function_t *_rehasher) {
  return CreateSGDOptions(_fbb, _o, _rehasher);
}

inline flatbuffers::Offset<SGDOptions> CreateSGDOptions(flatbuffers::FlatBufferBuilder &_fbb, const SGDOptionsT *_o, const flatbuffers::rehasher_function_t *_rehasher) {
  (void)_rehasher;
  (void)_o;
  struct _VectorArgs { flatbuffers::FlatBufferBuilder *__fbb; const SGDOptionsT* __o; const flatbuffers::rehasher_function_t *__rehasher; } _va = { &_fbb, _o, _rehasher}; (void)_va;
  auto _learning_rate = _o->learning_rate;
  return circle::CreateSGDOptions(
      _fbb,
      _learning_rate);
}

inline AdamOptionsT *AdamOptions::UnPack(const flatbuffers::resolver_function_t *_resolver) const {
  auto _o = std::unique_ptr<AdamOptionsT>(new AdamOptionsT());
  UnPackTo(_o.get(), _resolver);
  return _o.release();
}

inline void AdamOptions::UnPackTo(AdamOptionsT *_o, const flatbuffers::resolver_function_t *_resolver) const {
  (void)_o;
  (void)_resolver;
  { auto _e = learning_rate(); _o->learning_rate = _e; }
  { auto _e = beta_1(); _o->beta_1 = _e; }
  { auto _e = beta_2(); _o->beta_2 = _e; }
  { auto _e = epsilon(); _o->epsilon = _e; }
}

inline flatbuffers::Offset<AdamOptions> AdamOptions::Pack(flatbuffers::FlatBufferBuilder &_fbb, const AdamOptionsT* _o, const flatbuffers::rehasher_function_t *_rehasher) {
  return CreateAdamOptions(_fbb, _o, _rehasher);
}

inline flatbuffers::Offset<AdamOptions> CreateAdamOptions(flatbuffers::FlatBufferBuilder &_fbb, const AdamOptionsT *_o, const flatbuffers::rehasher_function_t *_rehasher) {
  (void)_rehasher;
  (void)_o;
  struct _VectorArgs { flatbuffers::FlatBufferBuilder *__fbb; const AdamOptionsT* __o; const flatbuffers::rehasher_function_t *__rehasher; } _va = { &_fbb, _o, _rehasher}; (void)_va;
  auto _learning_rate = _o->learning_rate;
  auto _beta_1 = _o->beta_1;
  auto _beta_2 = _o->beta_2;
  auto _epsilon = _o->epsilon;
  return circle::CreateAdamOptions(
      _fbb,
      _learning_rate,
      _beta_1,
      _beta_2,
      _epsilon);
}

inline SparseCategoricalCrossentropyOptionsT *SparseCategoricalCrossentropyOptions::UnPack(const flatbuffers::resolver_function_t *_resolver) const {
  auto _o = std::unique_ptr<SparseCategoricalCrossentropyOptionsT>(new SparseCategoricalCrossentropyOptionsT());
  UnPackTo(_o.get(), _resolver);
  return _o.release();
}

inline void SparseCategoricalCrossentropyOptions::UnPackTo(SparseCategoricalCrossentropyOptionsT *_o, const flatbuffers::resolver_function_t *_resolver) const {
  (void)_o;
  (void)_resolver;
  { auto _e = from_logits(); _o->from_logits = _e; }
}

inline flatbuffers::Offset<SparseCategoricalCrossentropyOptions> SparseCategoricalCrossentropyOptions::Pack(flatbuffers::FlatBufferBuilder &_fbb, const SparseCategoricalCrossentropyOptionsT* _o, const flatbuffers::rehasher_function_t *_rehasher) {
  return CreateSparseCategoricalCrossentropyOptions(_fbb, _o, _rehasher);
}

inline flatbuffers::Offset<SparseCategoricalCrossentropyOptions> CreateSparseCategoricalCrossentropyOptions(flatbuffers::FlatBufferBuilder &_fbb, const SparseCategoricalCrossentropyOptionsT *_o, const flatbuffers::rehasher_function_t *_rehasher) {
  (void)_rehasher;
  (void)_o;
  struct _VectorArgs { flatbuffers::FlatBufferBuilder *__fbb; const SparseCategoricalCrossentropyOptionsT* __o; const flatbuffers::rehasher_function_t *__rehasher; } _va = { &_fbb, _o, _rehasher}; (void)_va;
  auto _from_logits = _o->from_logits;
  return circle::CreateSparseCategoricalCrossentropyOptions(
      _fbb,
      _from_logits);
}

inline CategoricalCrossentropyOptionsT *CategoricalCrossentropyOptions::UnPack(const flatbuffers::resolver_function_t *_resolver) const {
  auto _o = std::unique_ptr<CategoricalCrossentropyOptionsT>(new CategoricalCrossentropyOptionsT());
  UnPackTo(_o.get(), _resolver);
  return _o.release();
}

inline void CategoricalCrossentropyOptions::UnPackTo(CategoricalCrossentropyOptionsT *_o, const flatbuffers::resolver_function_t *_resolver) const {
  (void)_o;
  (void)_resolver;
  { auto _e = from_logits(); _o->from_logits = _e; }
}

inline flatbuffers::Offset<CategoricalCrossentropyOptions> CategoricalCrossentropyOptions::Pack(flatbuffers::FlatBufferBuilder &_fbb, const CategoricalCrossentropyOptionsT* _o, const flatbuffers::rehasher_function_t *_rehasher) {
  return CreateCategoricalCrossentropyOptions(_fbb, _o, _rehasher);
}

inline flatbuffers::Offset<CategoricalCrossentropyOptions> CreateCategoricalCrossentropyOptions(flatbuffers::FlatBufferBuilder &_fbb, const CategoricalCrossentropyOptionsT *_o, const flatbuffers::rehasher_function_t *_rehasher) {
  (void)_rehasher;
  (void)_o;
  struct _VectorArgs { flatbuffers::FlatBufferBuilder *__fbb; const CategoricalCrossentropyOptionsT* __o; const flatbuffers::rehasher_function_t *__rehasher; } _va = { &_fbb, _o, _rehasher}; (void)_va;
  auto _from_logits = _o->from_logits;
  return circle::CreateCategoricalCrossentropyOptions(
      _fbb,
      _from_logits);
}

inline MeanSquaredErrorOptionsT *MeanSquaredErrorOptions::UnPack(const flatbuffers::resolver_function_t *_resolver) const {
  auto _o = std::unique_ptr<MeanSquaredErrorOptionsT>(new MeanSquaredErrorOptionsT());
  UnPackTo(_o.get(), _resolver);
  return _o.release();
}

inline void MeanSquaredErrorOptions::UnPackTo(MeanSquaredErrorOptionsT *_o, const flatbuffers::resolver_function_t *_resolver) const {
  (void)_o;
  (void)_resolver;
}

inline flatbuffers::Offset<MeanSquaredErrorOptions> MeanSquaredErrorOptions::Pack(flatbuffers::FlatBufferBuilder &_fbb, const MeanSquaredErrorOptionsT* _o, const flatbuffers::rehasher_function_t *_rehasher) {
  return CreateMeanSquaredErrorOptions(_fbb, _o, _rehasher);
}

inline flatbuffers::Offset<MeanSquaredErrorOptions> CreateMeanSquaredErrorOptions(flatbuffers::FlatBufferBuilder &_fbb, const MeanSquaredErrorOptionsT *_o, const flatbuffers::rehasher_function_t *_rehasher) {
  (void)_rehasher;
  (void)_o;
  struct _VectorArgs { flatbuffers::FlatBufferBuilder *__fbb; const MeanSquaredErrorOptionsT* __o; const flatbuffers::rehasher_function_t *__rehasher; } _va = { &_fbb, _o, _rehasher}; (void)_va;
  return circle::CreateMeanSquaredErrorOptions(
      _fbb);
}

inline ModelTrainingT *ModelTraining::UnPack(const flatbuffers::resolver_function_t *_resolver) const {
  auto _o = std::unique_ptr<ModelTrainingT>(new ModelTrainingT());
  UnPackTo(_o.get(), _resolver);
  return _o.release();
}

inline void ModelTraining::UnPackTo(ModelTrainingT *_o, const flatbuffers::resolver_function_t *_resolver) const {
  (void)_o;
  (void)_resolver;
  { auto _e = version(); _o->version = _e; }
  { auto _e = optimizer(); _o->optimizer = _e; }
  { auto _e = optimizer_opt_type(); _o->optimizer_opt.type = _e; }
  { auto _e = optimizer_opt(); if (_e) _o->optimizer_opt.value = circle::OptimizerOptionsUnion::UnPack(_e, optimizer_opt_type(), _resolver); }
  { auto _e = lossfn(); _o->lossfn = _e; }
  { auto _e = lossfn_opt_type(); _o->lossfn_opt.type = _e; }
  { auto _e = lossfn_opt(); if (_e) _o->lossfn_opt.value = circle::LossFnOptionsUnion::UnPack(_e, lossfn_opt_type(), _resolver); }
  { auto _e = epochs(); _o->epochs = _e; }
  { auto _e = batch_size(); _o->batch_size = _e; }
  { auto _e = loss_reduction_type(); _o->loss_reduction_type = _e; }
  { auto _e = trainable_ops(); if (_e) { _o->trainable_ops.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->trainable_ops[_i] = _e->Get(_i); } } }
}

inline flatbuffers::Offset<ModelTraining> ModelTraining::Pack(flatbuffers::FlatBufferBuilder &_fbb, const ModelTrainingT* _o, const flatbuffers::rehasher_function_t *_rehasher) {
  return CreateModelTraining(_fbb, _o, _rehasher);
}

inline flatbuffers::Offset<ModelTraining> CreateModelTraining(flatbuffers::FlatBufferBuilder &_fbb, const ModelTrainingT *_o, const flatbuffers::rehasher_function_t *_rehasher) {
  (void)_rehasher;
  (void)_o;
  struct _VectorArgs { flatbuffers::FlatBufferBuilder *__fbb; const ModelTrainingT* __o; const flatbuffers::rehasher_function_t *__rehasher; } _va = { &_fbb, _o, _rehasher}; (void)_va;
  auto _version = _o->version;
  auto _optimizer = _o->optimizer;
  auto _optimizer_opt_type = _o->optimizer_opt.type;
  auto _optimizer_opt = _o->optimizer_opt.Pack(_fbb);
  auto _lossfn = _o->lossfn;
  auto _lossfn_opt_type = _o->lossfn_opt.type;
  auto _lossfn_opt = _o->lossfn_opt.Pack(_fbb);
  auto _epochs = _o->epochs;
  auto _batch_size = _o->batch_size;
  auto _loss_reduction_type = _o->loss_reduction_type;
  auto _trainable_ops = _o->trainable_ops.size() ? _fbb.CreateVector(_o->trainable_ops) : 0;
  return circle::CreateModelTraining(
      _fbb,
      _version,
      _optimizer,
      _optimizer_opt_type,
      _optimizer_opt,
      _lossfn,
      _lossfn_opt_type,
      _lossfn_opt,
      _epochs,
      _batch_size,
      _loss_reduction_type,
      _trainable_ops);
}

inline bool VerifyOptimizerOptions(flatbuffers::Verifier &verifier, const void *obj, OptimizerOptions type) {
  switch (type) {
    case OptimizerOptions_NONE: {
      return true;
    }
    case OptimizerOptions_SGDOptions: {
      auto ptr = reinterpret_cast<const circle::SGDOptions *>(obj);
      return verifier.VerifyTable(ptr);
    }
    case OptimizerOptions_AdamOptions: {
      auto ptr = reinterpret_cast<const circle::AdamOptions *>(obj);
      return verifier.VerifyTable(ptr);
    }
    default: return true;
  }
}

inline bool VerifyOptimizerOptionsVector(flatbuffers::Verifier &verifier, const flatbuffers::Vector<flatbuffers::Offset<void>> *values, const flatbuffers::Vector<uint8_t> *types) {
  if (!values || !types) return !values && !types;
  if (values->size() != types->size()) return false;
  for (flatbuffers::uoffset_t i = 0; i < values->size(); ++i) {
    if (!VerifyOptimizerOptions(
        verifier,  values->Get(i), types->GetEnum<OptimizerOptions>(i))) {
      return false;
    }
  }
  return true;
}

inline void *OptimizerOptionsUnion::UnPack(const void *obj, OptimizerOptions type, const flatbuffers::resolver_function_t *resolver) {
  switch (type) {
    case OptimizerOptions_SGDOptions: {
      auto ptr = reinterpret_cast<const circle::SGDOptions *>(obj);
      return ptr->UnPack(resolver);
    }
    case OptimizerOptions_AdamOptions: {
      auto ptr = reinterpret_cast<const circle::AdamOptions *>(obj);
      return ptr->UnPack(resolver);
    }
    default: return nullptr;
  }
}

inline flatbuffers::Offset<void> OptimizerOptionsUnion::Pack(flatbuffers::FlatBufferBuilder &_fbb, const flatbuffers::rehasher_function_t *_rehasher) const {
  switch (type) {
    case OptimizerOptions_SGDOptions: {
      auto ptr = reinterpret_cast<const circle::SGDOptionsT *>(value);
      return CreateSGDOptions(_fbb, ptr, _rehasher).Union();
    }
    case OptimizerOptions_AdamOptions: {
      auto ptr = reinterpret_cast<const circle::AdamOptionsT *>(value);
      return CreateAdamOptions(_fbb, ptr, _rehasher).Union();
    }
    default: return 0;
  }
}

inline OptimizerOptionsUnion::OptimizerOptionsUnion(const OptimizerOptionsUnion &u) : type(u.type), value(nullptr) {
  switch (type) {
    case OptimizerOptions_SGDOptions: {
      value = new circle::SGDOptionsT(*reinterpret_cast<circle::SGDOptionsT *>(u.value));
      break;
    }
    case OptimizerOptions_AdamOptions: {
      value = new circle::AdamOptionsT(*reinterpret_cast<circle::AdamOptionsT *>(u.value));
      break;
    }
    default:
      break;
  }
}

inline void OptimizerOptionsUnion::Reset() {
  switch (type) {
    case OptimizerOptions_SGDOptions: {
      auto ptr = reinterpret_cast<circle::SGDOptionsT *>(value);
      delete ptr;
      break;
    }
    case OptimizerOptions_AdamOptions: {
      auto ptr = reinterpret_cast<circle::AdamOptionsT *>(value);
      delete ptr;
      break;
    }
    default: break;
  }
  value = nullptr;
  type = OptimizerOptions_NONE;
}

inline bool VerifyLossFnOptions(flatbuffers::Verifier &verifier, const void *obj, LossFnOptions type) {
  switch (type) {
    case LossFnOptions_NONE: {
      return true;
    }
    case LossFnOptions_SparseCategoricalCrossentropyOptions: {
      auto ptr = reinterpret_cast<const circle::SparseCategoricalCrossentropyOptions *>(obj);
      return verifier.VerifyTable(ptr);
    }
    case LossFnOptions_CategoricalCrossentropyOptions: {
      auto ptr = reinterpret_cast<const circle::CategoricalCrossentropyOptions *>(obj);
      return verifier.VerifyTable(ptr);
    }
    case LossFnOptions_MeanSquaredErrorOptions: {
      auto ptr = reinterpret_cast<const circle::MeanSquaredErrorOptions *>(obj);
      return verifier.VerifyTable(ptr);
    }
    default: return true;
  }
}

inline bool VerifyLossFnOptionsVector(flatbuffers::Verifier &verifier, const flatbuffers::Vector<flatbuffers::Offset<void>> *values, const flatbuffers::Vector<uint8_t> *types) {
  if (!values || !types) return !values && !types;
  if (values->size() != types->size()) return false;
  for (flatbuffers::uoffset_t i = 0; i < values->size(); ++i) {
    if (!VerifyLossFnOptions(
        verifier,  values->Get(i), types->GetEnum<LossFnOptions>(i))) {
      return false;
    }
  }
  return true;
}

inline void *LossFnOptionsUnion::UnPack(const void *obj, LossFnOptions type, const flatbuffers::resolver_function_t *resolver) {
  switch (type) {
    case LossFnOptions_SparseCategoricalCrossentropyOptions: {
      auto ptr = reinterpret_cast<const circle::SparseCategoricalCrossentropyOptions *>(obj);
      return ptr->UnPack(resolver);
    }
    case LossFnOptions_CategoricalCrossentropyOptions: {
      auto ptr = reinterpret_cast<const circle::CategoricalCrossentropyOptions *>(obj);
      return ptr->UnPack(resolver);
    }
    case LossFnOptions_MeanSquaredErrorOptions: {
      auto ptr = reinterpret_cast<const circle::MeanSquaredErrorOptions *>(obj);
      return ptr->UnPack(resolver);
    }
    default: return nullptr;
  }
}

inline flatbuffers::Offset<void> LossFnOptionsUnion::Pack(flatbuffers::FlatBufferBuilder &_fbb, const flatbuffers::rehasher_function_t *_rehasher) const {
  switch (type) {
    case LossFnOptions_SparseCategoricalCrossentropyOptions: {
      auto ptr = reinterpret_cast<const circle::SparseCategoricalCrossentropyOptionsT *>(value);
      return CreateSparseCategoricalCrossentropyOptions(_fbb, ptr, _rehasher).Union();
    }
    case LossFnOptions_CategoricalCrossentropyOptions: {
      auto ptr = reinterpret_cast<const circle::CategoricalCrossentropyOptionsT *>(value);
      return CreateCategoricalCrossentropyOptions(_fbb, ptr, _rehasher).Union();
    }
    case LossFnOptions_MeanSquaredErrorOptions: {
      auto ptr = reinterpret_cast<const circle::MeanSquaredErrorOptionsT *>(value);
      return CreateMeanSquaredErrorOptions(_fbb, ptr, _rehasher).Union();
    }
    default: return 0;
  }
}

inline LossFnOptionsUnion::LossFnOptionsUnion(const LossFnOptionsUnion &u) : type(u.type), value(nullptr) {
  switch (type) {
    case LossFnOptions_SparseCategoricalCrossentropyOptions: {
      value = new circle::SparseCategoricalCrossentropyOptionsT(*reinterpret_cast<circle::SparseCategoricalCrossentropyOptionsT *>(u.value));
      break;
    }
    case LossFnOptions_CategoricalCrossentropyOptions: {
      value = new circle::CategoricalCrossentropyOptionsT(*reinterpret_cast<circle::CategoricalCrossentropyOptionsT *>(u.value));
      break;
    }
    case LossFnOptions_MeanSquaredErrorOptions: {
      value = new circle::MeanSquaredErrorOptionsT(*reinterpret_cast<circle::MeanSquaredErrorOptionsT *>(u.value));
      break;
    }
    default:
      break;
  }
}

inline void LossFnOptionsUnion::Reset() {
  switch (type) {
    case LossFnOptions_SparseCategoricalCrossentropyOptions: {
      auto ptr = reinterpret_cast<circle::SparseCategoricalCrossentropyOptionsT *>(value);
      delete ptr;
      break;
    }
    case LossFnOptions_CategoricalCrossentropyOptions: {
      auto ptr = reinterpret_cast<circle::CategoricalCrossentropyOptionsT *>(value);
      delete ptr;
      break;
    }
    case LossFnOptions_MeanSquaredErrorOptions: {
      auto ptr = reinterpret_cast<circle::MeanSquaredErrorOptionsT *>(value);
      delete ptr;
      break;
    }
    default: break;
  }
  value = nullptr;
  type = LossFnOptions_NONE;
}

inline const circle::ModelTraining *GetModelTraining(const void *buf) {
  return flatbuffers::GetRoot<circle::ModelTraining>(buf);
}

inline const circle::ModelTraining *GetSizePrefixedModelTraining(const void *buf) {
  return flatbuffers::GetSizePrefixedRoot<circle::ModelTraining>(buf);
}

inline const char *ModelTrainingIdentifier() {
  return "CTR0";
}

inline bool ModelTrainingBufferHasIdentifier(const void *buf) {
  return flatbuffers::BufferHasIdentifier(
      buf, ModelTrainingIdentifier());
}

inline bool VerifyModelTrainingBuffer(
    flatbuffers::Verifier &verifier) {
  return verifier.VerifyBuffer<circle::ModelTraining>(ModelTrainingIdentifier());
}

inline bool VerifySizePrefixedModelTrainingBuffer(
    flatbuffers::Verifier &verifier) {
  return verifier.VerifySizePrefixedBuffer<circle::ModelTraining>(ModelTrainingIdentifier());
}

inline const char *ModelTrainingExtension() {
  return "circletr";
}

inline void FinishModelTrainingBuffer(
    flatbuffers::FlatBufferBuilder &fbb,
    flatbuffers::Offset<circle::ModelTraining> root) {
  fbb.Finish(root, ModelTrainingIdentifier());
}

inline void FinishSizePrefixedModelTrainingBuffer(
    flatbuffers::FlatBufferBuilder &fbb,
    flatbuffers::Offset<circle::ModelTraining> root) {
  fbb.FinishSizePrefixed(root, ModelTrainingIdentifier());
}

inline std::unique_ptr<circle::ModelTrainingT> UnPackModelTraining(
    const void *buf,
    const flatbuffers::resolver_function_t *res = nullptr) {
  return std::unique_ptr<circle::ModelTrainingT>(GetModelTraining(buf)->UnPack(res));
}

inline std::unique_ptr<circle::ModelTrainingT> UnPackSizePrefixedModelTraining(
    const void *buf,
    const flatbuffers::resolver_function_t *res = nullptr) {
  return std::unique_ptr<circle::ModelTrainingT>(GetSizePrefixedModelTraining(buf)->UnPack(res));
}

}  // namespace circle

#endif  // FLATBUFFERS_GENERATED_TRAININFO_CIRCLE_H_
